import { upsertVectors, VectorRecord } from '../libs/pinecone';
import { Pinecone } from '@pinecone-database/pinecone';
import fs from 'fs';
import path from 'path';
import dotenv from 'dotenv';

dotenv.config();

const pc = new Pinecone({
	apiKey: process.env.PINECONE_API_KEY!,
});

async function createIndexIfNeeded(indexName: string, dimension: number): Promise<boolean> {
	try {
		const indexList = await pc.listIndexes();
		const existingIndex = indexList.indexes?.find(
			(idx) => idx.name === indexName
		);

		if (existingIndex) {
			console.log(`Index '${indexName}' already exists`);
			if (existingIndex.dimension !== dimension) {
				console.warn(
					`‚ö†Ô∏è  Index dimension mismatch: expected ${dimension}, got ${existingIndex.dimension}`
				);
				console.log(
					`You may need to delete the existing index or use a different name`
				);
				return false;
			}
			return true;
		}

		console.log(
			`Creating index '${indexName}' with dimension ${dimension}...`
		);
		await pc.createIndex({
			name: indexName,
			dimension: dimension,
			metric: 'cosine',
			spec: {
				serverless: {
					cloud: 'aws',
					region: 'us-east-1',
				},
			},
		});

		console.log(`‚úÖ Index '${indexName}' created successfully`);
		return true;
	} catch (error) {
		console.error('Error managing index:', error);
		return false;
	}
}

async function uploadVectorsToPinecone(): Promise<void> {
	try {
		const batchInfoPath = path.join(process.cwd(), 'output', 'batch_info.json');
		
		if (!fs.existsSync(batchInfoPath)) {
			throw new Error(`Batch info file not found at: ${batchInfoPath}`);
		}

		console.log('Loading batch information...');
		const batchInfo = JSON.parse(fs.readFileSync(batchInfoPath, 'utf8'));
		
		console.log(`Found ${batchInfo.totalVectors} vectors in ${batchInfo.totalBatches} batches`);

		const indexName = process.env.PINECONE_INDEX_NAME;
		if (!indexName) {
			throw new Error('PINECONE_INDEX_NAME environment variable is required');
		}

		// Load first batch to get dimension
		const firstBatchPath = path.join(process.cwd(), 'output', batchInfo.batchFiles[0]);
		const firstBatch: VectorRecord[] = JSON.parse(fs.readFileSync(firstBatchPath, 'utf8'));
		const dimension = firstBatch[0].values.length;

		console.log(`Vector dimension: ${dimension}`);

		const indexReady = await createIndexIfNeeded(indexName, dimension);
		if (!indexReady) {
			throw new Error('Index is not ready for upload');
		}

		console.log(`Uploading to Pinecone index: ${indexName}`);

		// Process each batch file
		let totalUploaded = 0;
		for (let i = 0; i < batchInfo.batchFiles.length; i++) {
			const batchFile = batchInfo.batchFiles[i];
			const batchPath = path.join(process.cwd(), 'output', batchFile);
			
			console.log(`Processing batch ${i + 1}/${batchInfo.totalBatches}: ${batchFile}`);
			
			const batchVectors: VectorRecord[] = JSON.parse(fs.readFileSync(batchPath, 'utf8'));
			await upsertVectors(indexName, batchVectors);
			
			totalUploaded += batchVectors.length;
			console.log(`‚úÖ Uploaded batch ${i + 1}/${batchInfo.totalBatches} (${batchVectors.length} vectors)`);
		}

		console.log('‚úÖ Successfully uploaded all vectors to Pinecone!');
		console.log(`üìä Total uploaded: ${totalUploaded} vectors to index '${indexName}'`);
	} catch (error) {
		console.error('‚ùå Error uploading vectors:', error);
		process.exit(1);
	}
}

uploadVectorsToPinecone();